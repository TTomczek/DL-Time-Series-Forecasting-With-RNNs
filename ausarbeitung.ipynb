{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc33831cdcd3d27",
   "metadata": {},
   "source": [
    "# Time Series Forecasting mit rekurrenten neuronalen Netzen\n",
    "Dieses Notebook entsteht im Rahmen des Moduls `Deep Learning` an der Fachhochschule Südwestfalen. Es beschäftigt sich mit dem Thema `Time Series Forecasting` und untersucht die Anwendung von rekurrenten neuronalen Netzen (RNN) auf Zeitreihendaten...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec515710907f7ee3",
   "metadata": {},
   "source": [
    "## 1. Einleitung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dedd5c44055225",
   "metadata": {},
   "source": [
    "## 2. Was ist Time Series Forecasting (Zeitreihenvorhersage)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f7640-11d0-4c4a-8241-48b0ad583f53",
   "metadata": {},
   "source": [
    "Christian\n",
    "\n",
    "Definition gemäß https://www.studysmarter.de/studium/mathematik-studium/statistik-studium/zeitreihenprognose/ (27.12.2024):<br>\n",
    "**Zeitreihenprognose** ist eine statistische Methode zur Vorhersage zukünftiger Ereignisse oder Werte, indem historische Zeitreihendaten analysiert und Muster erkannt werden.\n",
    "\n",
    "Beispiele:<br>\n",
    "- Wetterdaten für zukünftiges Wetter (https://www.studysmarter.de/studium/mathematik-studium/statistik-studium/zeitreihenprognose/)\n",
    "- Aktienkurse für zukünftige Aktienverläufe\n",
    "- Passagierzahlen für zukünftige Passagiervorhersagen (https://data-science-crashkurs.de/chapters/kapitel_09.html)\n",
    "\n",
    "Die Seite https://www.emft.fraunhofer.de/de/kompetenzen/systemloesungen-ki/ki-algorithmen-zeitreihenanalyse.html nennt zudem noch folgende mögliche Beispiele:\n",
    "- Industrie 4.0 mit IIoT (Industrial Internet of Things)\n",
    "- Logistik\n",
    "- Finanzen\n",
    "- Stromnetze\n",
    "- Internetverkehr\n",
    "- Umweltmonitoring\n",
    "- Gesundheitsdaten\n",
    "\n",
    "Außerdem werden auf der Seite typische Methoden der künstlichen Intelligenz inklusive grafiscgenannt, wie z.B.: Regression, Klassifikation, Anomalieerkennung, Vorhersage\n",
    "\n",
    "Grafisches Beispiel einer Klassifikation:<br>\n",
    "<img style = 'border: 5px solid #555' src=\"Pictures/classification-dt-mls-emft.jpg\" width=\"30%\" alt=\"Grafisches Beispiel einer Klassifikation\"> \n",
    "<br>\n",
    "Grafisches Beispiel einer Anomalieerkennung:<br>\n",
    "<img style = 'border: 5px solid #555' src=\"Pictures/anomaly-dt-mls-emft.jpg\" width=\"30%\" alt=\"Grafisches Beispiel einer Anomalieerkennung\">\n",
    "<br>\n",
    "Grafisches Beispiel einer Anomalieerkennung:<br>\n",
    "<img style = 'border: 5px solid #555' src=\"Pictures/forecasting-dt-mls-emft.jpg\" width=\"30%\" alt=\"Grafisches Beispiel einer Vorhersage\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43de5d59607d0ce7",
   "metadata": {},
   "source": "## 3. Was sind recurrent neural networks (Rekurrente neuronale Netzwerke)?"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ein rekurrentes oder auch rückgekoppeltes neuronales Netzwerk (RNN) ist ein künstliches neuronales Netzwerk, dass bei jeder Verarbeitung einer Einheit auch ein Ergebnis aus einer früheren Iteration erhält. Damit eignet es sich besonders für die Verarbeitung von sequentiellen Daten, wie z.B. Zeitreihendaten, Text oder Sprache.\n",
    "Ein RNN funktioniert, indem es eine spezielle Ausgabe des vorherigen Schrittes, den hidden state oder auch state vector, als zusätzlichen Input für den nächsten Schritt verwendet. Das bedeutet, dass immer zwei Ausgaben generiert werden. Dadurch kann es sich an vorherige Iterationen erinnern und somit auch auf längere Abhängigkeiten in den Daten reagieren. Das eigentliche Ergebnis wird dabei nur im letzten Schritt betrachtet. [T1, S. 116ff]\n",
    "\n",
    "<img style = 'border: 5px solid #555' src=\"Pictures/rnn-ablauf.png\" width=\"30%\" alt=\"Ablauf eines RNN\">\n",
    "\n",
    "[T1, S. 117]\n",
    "\n",
    "Das Bild zeigt den sequentiellen Ablauf eines RNN. Dabei bezeichnet \"t\" den aktuellen Schritt. Diese Schritte könnten bei der Verarbeitung von Text z.B. einzelne Wörter oder Buchstaben sein. Der hidden state wird dabei in jedem Schritt aktualisiert und an den nächsten Schritt weitergegeben.\n",
    "\n",
    "Die Verarbeitung einer Interation erfolgt dabei in drei Schritten die in folgendem Bild dargestellt sind:\n",
    "\n",
    "<img style = 'border: 5px solid #555' src=\"Pictures/rnn-schritte.png\" width=\"30%\" alt=\"Ablauf einer RNN Iteration\">\n",
    "\n",
    "[T1, S. 119]\n",
    "\n",
    "Der erste Schritt verbindet die beiden Eingangsvektoren zu einem einzigen Vektor. Anschließend wird der hidden State aktualisiert und im letzten Schritt wird der Ausgabewert berechnet.\n",
    "\n",
    "Das vorangegangene Beispiel lässt sich mit wenigen Zeilen Code in PyTorch implementieren:"
   ],
   "id": "afca4b64d6396f5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:01:26.960801Z",
     "start_time": "2024-12-29T13:01:26.952647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))"
   ],
   "id": "11d26a24a50efddf",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T13:01:37.105913Z",
     "start_time": "2024-12-29T13:01:36.932650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "toy_story_review = ['just', 'perfect', 'script', 'character', 'animation', 'this', 'manages', 'to', 'break', 'free']\n",
    "input_size = 10\n",
    "hidden_size = 15\n",
    "output_size = 10\n",
    "\n",
    "rnn = RNN(input_size, hidden_size, output_size)\n",
    "hidden = rnn.initHidden()\n",
    "\n",
    "for i in range(len(toy_story_review)):\n",
    "    output, hidden = rnn(toy_story_review[i], hidden)"
   ],
   "id": "72b343fcfcb58a49",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m output_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[1;32m      6\u001B[0m rnn \u001B[38;5;241m=\u001B[39m RNN(input_size, hidden_size, output_size)\n\u001B[0;32m----> 7\u001B[0m hidden \u001B[38;5;241m=\u001B[39m \u001B[43mrnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minitHidden\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(toy_story_review)):\n\u001B[1;32m     10\u001B[0m     output, hidden \u001B[38;5;241m=\u001B[39m rnn(toy_story_review[i], hidden)\n",
      "Cell \u001B[0;32mIn[18], line 18\u001B[0m, in \u001B[0;36mRNN.initHidden\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minitHidden\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 18\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable(\u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Schleifenstruktur und Rückkopplung\n",
    "\n",
    "Mathematische Formeln\n",
    "\n",
    "Typen von RNNs\n",
    "Einfaches, Probleme\n",
    "LSTM\n",
    "GRU"
   ],
   "id": "772309f7532fb173"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Quellen:\n",
    "* T1: Mitchell, L. et al. (2019) Deep learning with Pytorch 1. x: implement deep learning techniques and neural network architecture variants using Python /. Second edition. Birmingham; Packt Publishing.\n"
   ],
   "id": "172359285f1e85b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e9ee09620b8c7589"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39524d29-fa5b-470a-b8f2-e3e9bed76849",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d24091bb38610",
   "metadata": {},
   "source": [
    "## 4. Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b7caefc4fc3ca",
   "metadata": {},
   "source": [
    "## 5. Implementierung eines RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4697ef4fcd6ea3f",
   "metadata": {},
   "source": [
    "## 6. Aktuelle Modelle\n",
    "Beispielmodelle Goldpreis oder Aktienpreis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353a46789790b6e9",
   "metadata": {},
   "source": [
    "## 7. Vergleich der Modelle\n",
    "Vergleich mit transformer-netwerken?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f09d9",
   "metadata": {},
   "source": [
    "## 8. Fazit\n",
    "Eigenes Modell vs. verglichene Standardmodelle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
