{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc33831cdcd3d27",
   "metadata": {},
   "source": [
    "# Time Series Forecasting mit rekurrenten neuronalen Netzen\n",
    "Dieses Notebook entsteht im Rahmen des Moduls `Deep Learning` an der Fachhochschule Südwestfalen. Es beschäftigt sich mit dem Thema `Time Series Forecasting` und untersucht die Anwendung von rekurrenten neuronalen Netzen (RNN) auf Zeitreihendaten...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec515710907f7ee3",
   "metadata": {},
   "source": [
    "## 1. Einleitung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dedd5c44055225",
   "metadata": {},
   "source": [
    "## 2. Was ist Time Series Forecasting (Zeitreihenvorhersage)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f7640-11d0-4c4a-8241-48b0ad583f53",
   "metadata": {},
   "source": [
    "Christian\n",
    "\n",
    "Definition gemäß der Webseite Studysmarter:<br>\n",
    "**Zeitreihenprognose** ist eine statistische Methode zur Vorhersage zukünftiger Ereignisse oder Werte, indem historische Zeitreihendaten analysiert und Muster erkannt werden. [C1]\n",
    "\n",
    "Beispiele:<br>\n",
    "- Wetterdaten für zukünftiges Wetter (https://www.studysmarter.de/studium/mathematik-studium/statistik-studium/zeitreihenprognose/)\n",
    "- Aktienkurse für zukünftige Aktienverläufe\n",
    "- Passagierzahlen für zukünftige Passagiervorhersagen (https://data-science-crashkurs.de/chapters/kapitel_09.html)\n",
    "\n",
    "Die Seite https://www.emft.fraunhofer.de/de/kompetenzen/systemloesungen-ki/ki-algorithmen-zeitreihenanalyse.html nennt zudem noch folgende mögliche Beispiele:\n",
    "- Industrie 4.0 mit IIoT (Industrial Internet of Things)\n",
    "- Logistik\n",
    "- Finanzen\n",
    "- Stromnetze\n",
    "- Internetverkehr\n",
    "- Umweltmonitoring\n",
    "- Gesundheitsdaten\n",
    "\n",
    "Außerdem werden auf der Seite typische Methoden der künstlichen Intelligenz inklusive grafischer Beispiele genannt, wie z.B.: Regression, Klassifikation, Anomalieerkennung, Vorhersage\n",
    "\n",
    "Grafisches Beispiel einer Klassifikation:<br>\n",
    "<img style = 'border: 5px solid #555' src=\"Pictures/classification-dt-mls-emft.jpg\" width=\"30%\" alt=\"Grafisches Beispiel einer Klassifikation\"> \n",
    "<br>\n",
    "Grafisches Beispiel einer Anomalieerkennung:<br>\n",
    "<img style = 'border: 5px solid #555' src=\"Pictures/anomaly-dt-mls-emft.jpg\" width=\"30%\" alt=\"Grafisches Beispiel einer Anomalieerkennung\">\n",
    "<br>\n",
    "Grafisches Beispiel einer Anomalieerkennung:<br>\n",
    "<img style = 'border: 5px solid #555' src=\"Pictures/forecasting-dt-mls-emft.jpg\" width=\"30%\" alt=\"Grafisches Beispiel einer Vorhersage\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa77e9-974d-453e-ae40-93c3d9e37a87",
   "metadata": {
    "tags": []
   },
   "source": [
    "Quellen:\n",
    "* C1: StudySmarter GmbH. (2024) Zeitreihenprognose: Methoden & Anwendung | StudySmarter. https://www.studysmarter.de/studium/mathematik-studium/statistik-studium/zeitreihenprognose/. 29.12.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43de5d59607d0ce7",
   "metadata": {},
   "source": [
    "## 3. Was sind recurrent neural networks (Rekurrente neuronale Netzwerke)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca4b64d6396f5d",
   "metadata": {},
   "source": [
    "Ein rekurrentes oder auch rückgekoppeltes neuronales Netzwerk (RNN) ist ein künstliches neuronales Netzwerk, dass bei jeder Verarbeitung einer Einheit auch ein Ergebnis aus einer früheren Iteration erhält. Damit eignet es sich besonders für die Verarbeitung von sequentiellen Daten, wie z.B. Zeitreihendaten, Text oder Sprache.\n",
    "Ein RNN funktioniert, indem es eine spezielle Ausgabe des vorherigen Schrittes, den hidden state oder auch state vector, als zusätzlichen Input für den nächsten Schritt verwendet. Das bedeutet, dass immer zwei Ausgaben generiert werden. Dadurch kann es sich an vorherige Iterationen erinnern und somit auch auf längere Abhängigkeiten in den Daten reagieren. Das eigentliche Ergebnis wird dabei nur im letzten Schritt betrachtet. [T1, S. 116ff]\n",
    "\n",
    "<img style = 'border: 5px solid #555' src=\"Pictures/rnn-ablauf.png\" width=\"30%\" alt=\"Ablauf eines RNN\">\n",
    "\n",
    "[T1, S. 117]\n",
    "\n",
    "Das Bild zeigt den sequentiellen Ablauf eines RNN. Dabei bezeichnet \"t\" den aktuellen Schritt. Diese Schritte könnten bei der Verarbeitung von Text z.B. einzelne Wörter oder Buchstaben sein. Der hidden state wird dabei in jedem Schritt aktualisiert und an den nächsten Schritt weitergegeben.\n",
    "\n",
    "Die Verarbeitung einer Interation erfolgt dabei in drei Schritten die in folgendem Bild dargestellt sind:\n",
    "\n",
    "<img style = 'border: 5px solid #555' src=\"Pictures/rnn-schritte.png\" width=\"30%\" alt=\"Ablauf einer RNN Iteration\">\n",
    "\n",
    "[T1, S. 119]\n",
    "\n",
    "Der erste Schritt verbindet die beiden Eingangsvektoren zu einem einzigen Vektor. Anschließend wird der hidden State aktualisiert und im letzten Schritt wird der Ausgabewert berechnet.\n",
    "\n",
    "Das vorangegangene Beispiel lässt sich mit wenigen Zeilen Code in PyTorch implementieren. Bei dem nachfolgenden Code handelt es lediglich um einen Auszug und nicht um ein vollständiges, lauffähiges Beispiel.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size) # input to hidden as linear layer\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size) # input to output as linear layer\n",
    "        self.softmax = nn.LogSoftmax(dim=1) # softmax function for output\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1) # concatenate input and hidden state\n",
    "        hidden = self.i2h(combined) # calculate new hidden state\n",
    "        output = self.i2o(combined) # calculate output\n",
    "        output = self.softmax(output) # apply softmax function\n",
    "        return output, hidden \n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size)) # initialize hidden state with zeros\n",
    "\n",
    "# Run the RNN\n",
    "rnn = RNN(input_size, hidden_size, output_size)\n",
    "hidden = rnn.initHidden() # initialize hidden state\n",
    "\n",
    "for i in range(len(toy_story_review)):\n",
    "    output, hidden = rnn(toy_story_review[i], hidden) # process each word in the review\n",
    "```\n",
    "[T1, S. 118]\n",
    "\n",
    "Da ein RNN nun auch eine Zeitkomponente mit bringt, ist der normale Backpropagation Algorithmus nicht anwendbar, da dieser die Schritte des RNN nicht berücksichtigen kann.\n",
    "Die Formel für den Backpropagation Algorithmus lautet:\n",
    "$$ \\Delta w_{ij} = -\\eta \\frac{\\partial E}{\\partial w_{ij}} $$\n",
    "Dabei ist $ \\Delta w_{ij} $ das gewicht zwischen den Neuronen i und j, $ \\eta $ die Lernrate und $ \\partial E $ der Fehler der Fehlerfunktion (Loss).\n",
    "\n",
    "\n",
    "Um dieses Problem zu lösen wurde der \"Backpropagation through time\" Algorithmus entwickelt. Dieser besteht aus vier Schritten:\n",
    "\n",
    "Zuerst wird der Fehler $ \\delta_t $ für jeden Zeitschritt berechnet. Dieser wird mit der Ableitung der Aktivierungsfunktion $ g'(y_t) $ multipliziert. Als aktivierungsfunktion verwendet man üblicherweise die Tanh-Funktion.\n",
    "$$ \\delta_t = \\frac{\\partial E}{\\partial y_t} \\cdot g'(y_t) $$\n",
    "\n",
    "Anschließend wird der Gradient für jeden Zeitschritt berechnet, indem die zuvor berechneten Fehler $ \\delta_t $ mit dem hidden statedes Zeitschritts $ \\cdot h_t^T $ multipliziert und anschließend aufsummiert werden.\n",
    "$$ \\Delta W_y = \\sum_{t} \\delta_t \\cdot h_t^T $$\n",
    "\n",
    "Danach wird der Gradient des hidden state $ \\Delta W_h $ berechnet. Dafür wird der Fehler $ \\delta_t $ mit der Ableitung des hidden state multipliziert und wieder über alle Zeitschritte aufsummiert.\n",
    "$$ \\Delta W_h = \\sum_{t} \\delta_t \\cdot \\frac{\\partial h_t}{\\partial W_h} $$\n",
    "\n",
    "Zuletzt wird der Gradient des Eingangsvektors berechnet. Dies geschieht analog zum vorherigen Schritt, nur dass hier der Fehler $ \\delta_t $ mit der Ableitung des Eingangsvektors $ \\delta W_x $, anstatt dem hidden state $ \\delta W_h $, multipliziert wird.\n",
    "$$ \\Delta W_x = \\sum_{t} \\delta_t \\cdot \\frac{\\partial h_t}{\\partial W_x} $$\n",
    "\n",
    "Diese einfache Form von RNNs hat jedoch zwei Probleme, die als Vanishing und Exploding Gradient Problem bekannt sind. Diese treten auf, wenn eine große Sequenz an Daten verarbeitet werden soll. Bei diesen Problemen werden die Gradienten entweder zu klein oder zu groß, um sinnvolle Änderungen an den Gewichten vornehmen zu können. Dadurch kann das RNN keine langfristigen Abhängigkeiten in den Daten erkennen. Um dieses Problem zu lösen, gibt es verschiedene Ansätze wie zum Beispiel das Gradient Clipping, was die Werte der Gradienten mit einem Maximal- und einem Minimalwert begrenzt, oder der Einsatz von Normalisierungstechniken wie dem Layer Normalization oder dem Batch Normalization. [T2, S. 275ff]\n",
    "In realen Anwendungsszenarien werden jedoch speziell aufgrund dieser Probleme entwickelte Netzwerke wie das Long Short-Term Memory (LSTM) oder das Gated Recurrent Unit (GRU) verwendet. Diese Netzwerke sind in der Lage, langfristige Abhängigkeiten in den Daten zu erkennen und zu verarbeiten.\n",
    "\n",
    "Das Long Short-Term Memory (LSTM) Netzwerk wurde 1997 von Sepp Hochreiter und Jürgen Schmidhuber entwickelt, um die Probleme des einfachen RNN zu lösen.\n",
    "Dabei ist folgende Architektur entstanden:\n",
    "\n",
    " <img style = 'border: 5px solid #555' src=\"Pictures/lstm-zelle.png\" width=\"50%\" alt=\"Architektur eines LSTM\">\n",
    " \n",
    " [T2, S. 407]\n",
    " \n",
    "Oben in der Abbildung ist eine gerade Linie, vom Eingang c(t-1), zu sehen, die mit nur wenigen Schritten Informationen weitergibt. Dies ist das \"Langzeitgedächtnis\" (L) des LSTM. Dieses passiert zuerst das sogenannte \"Forget-Gate\", wo mittels einer elementweisen Multiplikation entschieden wird welche Information vergessen werden soll. Die Entscheidung welche Information vergessen werden soll, wird durch die Sigmoid (logistische) Funktion f(t) entschieden die nach einer linearen Schicht auf die Daten des \"Kurzzeitgedächtnisses\" (S) h(t-1) zusammen mit dne aktuellen Eingabedaten x(t) angewendet wird. Anschließend wird über die Tanh Funktion g(t), wieder nach einer linearen Schicht mit den Daten aus h(t-1) und x(t), entschieden welche neuen Informationen in das Langzeitgedächtnis übernommen werden sollen. Zuvor werden diese Daten noc h durch eine weitere Sigmoid Funktion i(t) gefiltert. Das Langzeitgedächtnis wird ab dieser Stelle nicht mehr verändert und kann ausgegeben werden. Das Kurzzeitgedächtnis durch eine Tanh Funktion und einer Sigmoid Funktion o(t) gefiltert und ausgegeben. Die Sigmoid Funktion o(t) entscheidet dabei welche Informationen aus dem Langzeitgedächtnis ausgegeben werden sollen. Dieses Ergebnis ergibt dann das neue Kurzzeitgedächtnis h(t), dass an den nächsten Schritt weitergegeben werden kann, und das aktuelle Ergebnis y(t). [T2, S. 406ff]\n",
    "\n",
    "Eine neuere Variante des LSTM ist das Gated Recurrent Unit (GRU). Dieses wurde 2014 von Kyunghyun Cho et al. entwickelt und ist eine vereinfachte Version des LSTM. Es besteht aus zwei Gates, dem Reset-Gate (Forget-Gate) und dem Update-Gate (Eingabe-Gate). Das Reset-Gate entscheidet, welche Informationen vergessen werden sollen, und das Update-Gate entscheidet, welche Informationen im hidden state behalten werden sollen. [T2, S. 410]\n",
    "\n",
    "Die Architektur des GRU sieht folgendermaßen aus:\n",
    "\n",
    "<img style = 'border: 5px solid #555' src=\"Pictures/gru-zelle.png\" width=\"50%\" alt=\"Architektur eines GRU\">\n",
    "\n",
    "[T2, S. 410]\n",
    "\n",
    "Im Vergleich zum LSTM ist weniger komplex. Der auffälligste Unterschied ist das Fehlen des Langzeitgedächtnisses. Beim GRU werden Lang- und Kurzzeitgedächtnis in einem hidden state zusammengefasst. Das Reset- und das Update-Gate werden dabei durch einen einzigen Controller, einer linearen Schicht und einer Sigmoid Funktion z(t), gesteuert. Dabei wird das Ergebnis für das Forget-Gate negiert. Wird eine Information hinzugefügt, wird als Gegenteil zuvor eine andere vergessen. Die Informationen die hinzugefügt werden sollen stammen aus einer Tanh Funktion und einer Sigmoid Funktion r(t). Beim GRU entspricht dann der hidden state auch dem Ausgabewert. [T2, S. 410]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172359285f1e85b9",
   "metadata": {},
   "source": [
    "Quellen:\n",
    "* T1: Mitchell, L. et al. (2019) Deep learning with Pytorch 1. x: implement deep learning techniques and neural network architecture variants using Python /. Second edition. Birmingham; Packt Publishing.\n",
    "* T2: Géron, A. & Rother, K. (2018) Praxiseinstieg Machine Learning mit Scikit-Learn und TensorFlow: Konzepte, Tools und Techniken für intelligente Systeme. 1. Auflage. Heidelberg: O’Reilly.\n",
    "* T3: Sepp Hochreiter, Jürgen Schmidhuber; Long Short-Term Memory. Neural Comput 1997; 9 (8): 1735–1780. doi: https://doi.org/10.1162/neco.1997.9.8.1735\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d24091bb38610",
   "metadata": {},
   "source": [
    "## 4. Datenbeschaffung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff8acc01023e34",
   "metadata": {},
   "source": [
    "Für die folgenden Implementierungen verschiedener RNNs wird ein Datensatz der Plattform \"Kaggle\" [T5] verwendet. Kaggle ist eine Plattform der Google LLC und bietet eine Vielzahl von Datensätzen und Modellen für Machine Learning und Data Science Projekte aber auch Wettbewerbe und Kurse an. An dieser Stelle sei noch auf die Plattform \"Hugging Face\" [T6] erwähnt, die ebenfalls eine Vielzahl von Modellen und Datensätzen für Machine Learning und Data Science Projekte anbietet.\n",
    "\n",
    "Der verwendeten Daten \"Gold and Silver prices (2013-2024)\" beinhaltet den täglichen Goldpreis von 2013 bis zum November 2024. Der Datensatz wurde von Alexander Kapturov unter der CC0: Public Domain Lizenz veröffentlicht, wodurch er für alle Zwecke frei verwendet werden kann.\n",
    "\n",
    "Der Datensatz wird als CSV-Datei bereitgestellt und beinhaltet folgende Spalten:\n",
    "* Date: Das Datum des Datensatzes im Format mm/DD/yyyy\n",
    "* Close/Last: Der Schlusskurs des Goldpreises in US-Dollar pro Unze\n",
    "* Volume: Das gehandelte Volumen des Goldes in Unzen\n",
    "* Open: Der Eröffnungskurs des Goldpreises in US-Dollar pro Unze\n",
    "* High: Der höchste Kurs des Goldpreises an diesem Tag in US-Dollar pro Unze\n",
    "* Low: Der niedrigste Kurs des Goldpreises an diesem Tag in US-Dollar pro Unze\n",
    "\n",
    "Für die weitere Analyse wird der Datensatz in ein Pandas DataFrame geladen. Dabei wird die Spalte date als index genutzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183f590768c3003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T17:30:09.038171Z",
     "start_time": "2025-01-03T17:30:08.194451Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close/Last</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2539.000000</td>\n",
       "      <td>2511.000000</td>\n",
       "      <td>2539.000000</td>\n",
       "      <td>2539.000000</td>\n",
       "      <td>2539.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1467.437456</td>\n",
       "      <td>183765.289128</td>\n",
       "      <td>1467.455967</td>\n",
       "      <td>1477.035880</td>\n",
       "      <td>1457.630721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>282.891621</td>\n",
       "      <td>98028.942525</td>\n",
       "      <td>283.126968</td>\n",
       "      <td>285.232942</td>\n",
       "      <td>280.366732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1049.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1051.500000</td>\n",
       "      <td>1062.700000</td>\n",
       "      <td>1045.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1243.900000</td>\n",
       "      <td>123166.500000</td>\n",
       "      <td>1243.850000</td>\n",
       "      <td>1251.250000</td>\n",
       "      <td>1235.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1321.400000</td>\n",
       "      <td>172127.000000</td>\n",
       "      <td>1321.700000</td>\n",
       "      <td>1329.300000</td>\n",
       "      <td>1314.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1774.050000</td>\n",
       "      <td>233415.000000</td>\n",
       "      <td>1773.950000</td>\n",
       "      <td>1785.000000</td>\n",
       "      <td>1763.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2069.400000</td>\n",
       "      <td>787217.000000</td>\n",
       "      <td>2076.400000</td>\n",
       "      <td>2085.400000</td>\n",
       "      <td>2049.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Close/Last         Volume         Open         High          Low\n",
       "count  2539.000000    2511.000000  2539.000000  2539.000000  2539.000000\n",
       "mean   1467.437456  183765.289128  1467.455967  1477.035880  1457.630721\n",
       "std     282.891621   98028.942525   283.126968   285.232942   280.366732\n",
       "min    1049.600000       1.000000  1051.500000  1062.700000  1045.400000\n",
       "25%    1243.900000  123166.500000  1243.850000  1251.250000  1235.800000\n",
       "50%    1321.400000  172127.000000  1321.700000  1329.300000  1314.000000\n",
       "75%    1774.050000  233415.000000  1773.950000  1785.000000  1763.550000\n",
       "max    2069.400000  787217.000000  2076.400000  2085.400000  2049.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Data/gold_prices.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a314196-4d3a-4103-beaa-12028c8a594a",
   "metadata": {},
   "source": [
    "Die Funktion describe gibt einen Überblick über die Daten, indem sie verschiedene Werte über die Daten anzeigt.\n",
    "In der ersten Zeile sehen wir die Anzahl der Einträge die nicht NULL sind. Dort sehen wir auch ein erstes Problem. Anscheinend fehlt für 28 Tage das gehandelte Volumen.\n",
    "Die Zeile mean zeigt den Mittelwert der Daten.\n",
    "Die Zeile std zeigt die Standardabweichung.\n",
    "Die Zeilen min und max zeigen jeweils den niedrigsten und höchsten Wert der Spalte an.\n",
    "Die Zeilen mit den Prozentwerten geben an, dass x prozent der Daten unter diesem Wert liegen oder ihm genau entsprechen.\n",
    "Man sieht außerdem das die Werte für das Volumen meistens deutlich größer sind als die Preise. Dieser Unterschied der Wertebereiche verschelchtert das Training und sollte daher vor der Nutzung in einem Modell skaliert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4865b6-bb13-4f7d-ba45-20ec60376544",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2539"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3d58da-60fd-4e87-98f3-c9c8855f7c4a",
   "metadata": {},
   "source": [
    "Der Datensatz insgesamt 2539 Einträge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ca79b5-d7cd-4c64-a495-bf255ee819a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  Close/Last  Volume    Open    High     Low\n",
      "208   10/18/2022      1655.5     NaN  1655.5  1655.5  1655.5\n",
      "210   10/14/2022      1672.9     NaN  1672.9  1672.9  1672.9\n",
      "211   10/13/2022      1672.9     NaN  1672.9  1672.9  1672.9\n",
      "853   03/27/2020      1623.9     NaN  1623.9  1623.9  1623.9\n",
      "1191  11/21/2018      1225.8     NaN  1225.8  1225.8  1225.8\n",
      "1236  09/19/2018      1202.2     NaN  1202.2  1202.2  1202.2\n",
      "1924  12/25/2015      1075.9     NaN  1075.9  1075.9  1075.9\n",
      "1945  11/26/2015      1069.7     NaN  1069.7  1069.7  1069.7\n",
      "2003  09/07/2015      1121.4     NaN  1121.4  1121.4  1121.4\n",
      "2049  07/03/2015      1163.5     NaN  1163.5  1163.5  1163.5\n",
      "2078  05/25/2015      1204.0     NaN  1204.0  1204.0  1204.0\n",
      "2114  04/03/2015      1200.9     NaN  1200.9  1200.9  1200.9\n",
      "2148  02/16/2015      1227.1     NaN  1227.1  1227.1  1227.1\n",
      "2168  01/19/2015      1276.9     NaN  1276.9  1276.9  1276.9\n",
      "2180  01/01/2015      1184.1     NaN  1184.1  1184.1  1184.1\n",
      "2185  12/25/2014      1173.5     NaN  1173.5  1173.5  1173.5\n",
      "2205  11/27/2014      1197.5     NaN  1197.5  1197.5  1197.5\n",
      "2268  09/01/2014      1287.4     NaN  1287.4  1287.4  1287.4\n",
      "2309  07/04/2014      1320.6     NaN  1320.6  1320.6  1320.6\n",
      "2338  05/26/2014      1291.9     NaN  1291.9  1291.9  1291.9\n",
      "2364  04/18/2014      1293.9     NaN  1293.9  1293.9  1293.9\n",
      "2408  02/17/2014      1318.6     NaN  1318.6  1318.6  1318.6\n",
      "2428  01/20/2014      1251.9     NaN  1251.9  1251.9  1251.9\n",
      "2441  01/01/2014      1202.3     NaN  1202.3  1202.3  1202.3\n",
      "2446  12/25/2013      1203.3     NaN  1203.3  1203.3  1203.3\n",
      "2465  11/28/2013      1237.9     NaN  1237.9  1237.9  1237.9\n",
      "2486  10/30/2013      1349.3     NaN  1343.1  1349.3  1349.3\n",
      "2528  09/02/2013      1396.1     NaN  1396.1  1396.1  1396.1\n"
     ]
    }
   ],
   "source": [
    "null_values = df.isnull().any(axis=1) # Suche auf Achse 1 (Spalten) nach NULL-Werten\n",
    "null_rows = df[null_values] # Hole alle Zeilen der Datensätze mit NULL-Werten\n",
    "\n",
    "print(null_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be08093-f898-40ce-b670-3fd9e5df7483",
   "metadata": {},
   "source": [
    "Hier haben wir nun alle Zeilen ohne einen Wert in mindestens einer Spalte. Die fehlenden Werte sind zufällig und nicht zusammenhängend. Betrachten wir für den obersten Datensatz die umliegenden Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66cfef75-eadf-458a-8864-b0b400d36151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close/Last</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>10/20/2022</td>\n",
       "      <td>1636.8</td>\n",
       "      <td>159797.0</td>\n",
       "      <td>1634.6</td>\n",
       "      <td>1650.3</td>\n",
       "      <td>1626.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>10/19/2022</td>\n",
       "      <td>1634.2</td>\n",
       "      <td>172551.0</td>\n",
       "      <td>1657.2</td>\n",
       "      <td>1659.8</td>\n",
       "      <td>1632.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>10/18/2022</td>\n",
       "      <td>1655.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1655.5</td>\n",
       "      <td>1655.5</td>\n",
       "      <td>1655.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>10/17/2022</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>144374.0</td>\n",
       "      <td>1649.9</td>\n",
       "      <td>1674.3</td>\n",
       "      <td>1649.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>10/14/2022</td>\n",
       "      <td>1672.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1672.9</td>\n",
       "      <td>1672.9</td>\n",
       "      <td>1672.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Close/Last    Volume    Open    High     Low\n",
       "206  10/20/2022      1636.8  159797.0  1634.6  1650.3  1626.3\n",
       "207  10/19/2022      1634.2  172551.0  1657.2  1659.8  1632.2\n",
       "208  10/18/2022      1655.5       NaN  1655.5  1655.5  1655.5\n",
       "209  10/17/2022      1664.0  144374.0  1649.9  1674.3  1649.1\n",
       "210  10/14/2022      1672.9       NaN  1672.9  1672.9  1672.9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[206:211]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bcbb03-e10a-4650-880a-b120a4129123",
   "metadata": {},
   "source": [
    "Man kann sehen, dass an den Tagen vor und nach den Tagen ohne Werte Handel stattgefunden hat, da diese ein Volumen angegeben haben und auch verschiedene Werte für die einzelnen Spalten haben. Die Datensätze mit fehlendem Umsatz haben in allen Spalten den gleichen Wert. Man kann also davon ausgehen, dass an diesen tagen kein Handel stattgefunden hat. Daher können die fehlenden Werte durch den Wert 0 ersetzt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a0ac98b8c68268",
   "metadata": {},
   "source": [
    "Quellen:\n",
    "* T4: https://www.kaggle.com/datasets/kapturovalexander/gold-and-silver-prices-2013-2023, [Online, Stand: 03.01.2025]\n",
    "* T5: https://www.kaggle.com/, [Online, Stand: 03.01.2025]\n",
    "* T6: https://huggingface.co/, [Online, Stand: 03.01.2025]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b7caefc4fc3ca",
   "metadata": {},
   "source": [
    "## 5. Implementierung eines RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4697ef4fcd6ea3f",
   "metadata": {},
   "source": [
    "## 6. Aktuelle Modelle\n",
    "Beispielmodelle Goldpreis oder Aktienpreis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353a46789790b6e9",
   "metadata": {},
   "source": [
    "## 7. Vergleich der Modelle\n",
    "Vergleich mit transformer-netwerken?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f09d9",
   "metadata": {},
   "source": [
    "## 8. Fazit\n",
    "Eigenes Modell vs. verglichene Standardmodelle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
